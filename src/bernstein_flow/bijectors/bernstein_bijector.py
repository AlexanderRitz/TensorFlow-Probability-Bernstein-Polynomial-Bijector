#!env python3
# AUTHOR INFORMATION ##########################################################
# file   : bernstein_bijector.py
# brief  : [Description]
#
# author : Marcel Arpogaus
# date   : 2020-09-11 14:14:24
# COPYRIGHT ###################################################################
# Copyright 2020 Marcel Arpogaus
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# NOTES ######################################################################
#
# This project is following the
# [PEP8 style guide](https://www.python.org/dev/peps/pep-0008/)
#
# CHANGELOG ##################################################################
# modified by   : Marcel Arpogaus
# modified time : 2020-10-14 20:24:44
#  changes made : ...
# modified by   : Marcel Arpogaus
# modified time : 2020-09-11 14:14:24
#  changes made : newly written
###############################################################################

# REQUIRED PYTHON MODULES #####################################################
import scipy.interpolate as I

import numpy as np
import tensorflow as tf

from tensorflow_probability import distributions as tfd
from tensorflow_probability import bijectors as tfb

from tensorflow_probability.python.internal import dtype_util
from tensorflow_probability.python.internal import tensor_util


class BernsteinBijector(tfb.Bijector):
    """
    Implementing Bernstein polynomials using the `tfb.Bijector` interface for
    transformations of a `Distribution` sample.
    """

    def __init__(self,
                 order: int,
                 theta: tf.Tensor,
                 validate_args: bool = False,
                 name: str = 'bernstein_bijector'):
        """
        Constructs a new instance of a Bernstein polynomial bijector.

        :param      order:          The order of the Bernstein polynomial.
        :type       order:          int
        :param      theta:          The Bernstein coefficients.
        :type       theta:          Tensor
        :param      validate_args:  Whether to validate input with asserts.
                                    Passed to `super()`.
        :type       validate_args:  bool
        :param      name:           The name to give Ops created by the
                                    initializer. Passed to `super()`.
        :type       name:           str
        """
        with tf.name_scope(name) as name:
            dtype = dtype_util.common_dtype([theta], dtype_hint=tf.float32)

            super().__init__(
                forward_min_event_ndims=0,
                is_constant_jacobian=True,
                validate_args=validate_args,
                dtype=dtype,
                name=name)

            # Bernstein coefficients
            order = order
            self.M = order - 1
            self.theta = tensor_util.convert_nonref_to_tensor(
                theta, dtype=dtype, name='shift')

            # Bernstein polynomials of order M,
            # generated by the M + 1 beta-densities
            self.beta_dist_h = tfd.Beta(
                range(1, order + 1), range(order, 0, -1))

            # Deviation of the Bernstein polynomials
            self.beta_dist_h_dash = tfd.Beta(
                range(1, self.M + 1), range(self.M, 0, -1))

            # Cubic splines are used to approximate the inverse
            self.interp = None

    def gen_inverse_interpolation(self) -> None:
        """
        Generates the Spline Interpolation.
        """
        y_fit = np.linspace(.0, 1, self.M * 10,
                            dtype=np.float32)

        z_fit = self.forward(y_fit)
        self.z_min = np.min(z_fit)
        self.z_max = np.max(z_fit)

        interp = I.interp1d(
            x=np.squeeze(z_fit),
            y=np.squeeze(y_fit),
            kind='cubic'
        )

        def ifn(x):
            return interp(x).astype(np.float32)

        self.interp = ifn

    def _inverse(self, z: tf.Tensor) -> tf.Tensor:
        """
        Returns the inverse Bijector evaluation.

        :param      z:    The input to the inverse evaluation.
        :type       z:    Tensor

        :returns:   The inverse Bijector evaluation.
        :rtype:     Tensor
        """
        if tf.executing_eagerly():
            if self.interp is None:
                self.gen_inverse_interpolation()
            z = tf.clip_by_value(z, self.z_min + 1E-5, self.z_max - 1E-5)
            return self.interp(z)
        else:
            return z

    def _forward(self, y: tf.Tensor) -> tf.Tensor:
        """
        Returns the forward Bijector evaluation.

        :param      y:    The input to the forward evaluation.
        :type       y:    Tensor

        :returns:   The forward Bijector evaluation.
        :rtype:     Tensor
        """
        y = tf.clip_by_value(y, 1E-5, 1.0 - 1E-5)
        by = self.beta_dist_h.prob(y[..., None])
        z = tf.reduce_mean(by * self.theta, axis=-1)

        return z

    def _forward_log_det_jacobian(self, y):
        y = tf.clip_by_value(y, 1E-5, 1.0 - 1E-5)
        by = self.beta_dist_h_dash.prob(y[..., None])
        dtheta = self.theta[..., 1:] - self.theta[..., 0:-1]
        ldj = tf.math.log(tf.reduce_sum(by * dtheta, axis=-1))

        return ldj

    @classmethod
    def constrain_theta(cls: type,
                        theta_unconstrained: tf.Tensor,
                        fn=tf.math.softplus) -> tf.Tensor:
        """
        Class method to calculate theta_1 = h_1, theta_k = theta_k-1 + exp(h_k)

        :param      cls:                  The class as implicit first argument.
        :type       cls:                  type
        :param      theta_unconstrained:  The unconstrained Bernstein
                                          coefficients.
        :type       theta_unconstrained:  Tensor
        :param      fn:                   The used activation function.
        :type       fn:                   Function

        :returns:   The constrained Bernstein coefficients.
        :rtype:     Tensor
        """
        d = tf.concat((tf.zeros_like(theta_unconstrained[..., :1]),
                       theta_unconstrained[..., :1],
                       fn(theta_unconstrained[..., 1:])), axis=-1)
        return tf.cumsum(d[..., 1:], axis=-1)
